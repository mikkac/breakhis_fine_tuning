{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BreakHis Image Classification with ðŸ¤— Vision Transformers and `TensorFlow`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick intro: Vision Transformer (ViT) by Google Brain\n",
    "The Vision Transformer (ViT) is basically BERT, but applied to images. It attains excellent results compared to state-of-the-art convolutional networks. In order to provide images to the model, each image is split into a sequence of fixed-size patches (typically of resolution 16x16 or 32x32), which are linearly embedded. One also adds a [CLS] token at the beginning of the sequence in order to classify images. Next, one adds absolute position embeddings and provides this sequence to the Transformer encoder.\n",
    "\n",
    "* [Original paper](https://arxiv.org/abs/2010.11929)\n",
    "* [Official repo (in JAX)](https://github.com/google-research/vision_transformer)\n",
    "* [ðŸ¤— Vision Transformer](https://huggingface.co/docs/transformers/model_doc/vit)\n",
    "* [Pre-trained model](https://huggingface.co/google/vit-base-patch16-224-in21k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets tensorflow-addons --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration\n",
    "\n",
    "In this step, we will define global configurations and parameters, which are used across the whole end-to-end fine-tuning process, e.g. `feature extractor` and `model` we will use. \n",
    "\n",
    "In this example we are going to fine-tune the [google/vit-base-patch16-224-in21k](https://huggingface.co/google/vit-base-patch16-224-in21k) a Vision Transformer (ViT) pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224.\n",
    "There are also [large](https://huggingface.co/google/vit-large-patch16-224-in21k) and [huge](https://huggingface.co/google/vit-huge-patch14-224-in21k) flavors of original ViT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 18:33:44.523010: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNextImageProcessor {\n",
       "  \"crop_pct\": 0.875,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFAutoModelForImageClassification, AutoImageProcessor, TFConvNextForImageClassification\n",
    "\n",
    "model_id = \"facebook/convnext-base-224-22k\"\n",
    "# model_id = \"microsoft/swin-base-patch4-window7-224-in22k\"\n",
    "\n",
    "model_arch = TFConvNextForImageClassification\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_id)\n",
    "\n",
    "zoom = 400\n",
    "\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from transformers import create_optimizer, DefaultDataCollator, ViTImageProcessor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Pre-processing\n",
    "\n",
    "- **Data Source:** https://www.kaggle.com/code/nasrulhakim86/breast-cancer-histopathology-images-classification/data\n",
    "- The Breast Cancer Histopathological Image Classification (BreakHis) is composed of 9,109 microscopic images of breast tumor tissue collected from 82 patients.\n",
    "- The images are collected using different magnifying factors (40X, 100X, 200X, and 400X). \n",
    "- To date, it contains 2,480 benign and 5,429 malignant samples (700X460 pixels, 3-channel RGB, 8-bit depth in each channel, PNG format).\n",
    "- This database has been built in collaboration with the P&D Laboratory â€“ Pathological Anatomy and Cytopathology, Parana, Brazil (http://www.prevencaoediagnose.com.br). \n",
    "- Each image filename stores information about the image itself: method of procedure biopsy, tumor class, tumor type, patient identification, and magnification factor. \n",
    "- For example, SOBBTA-14-4659-40-001.png is the image 1, at magnification factor 40X, of a benign tumor of type tubular adenoma, original from the slide 14-4659, which was collected by procedure SOB."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BreakHis` is not yet available as a dataset in the `datasets` library. To be able to create a `Dataset` instance we need to write a small little helper function, which will load our `Dataset` from the filesystem and create the instance to use later for training.\n",
    "\n",
    "This notebook assumes that the dataset is available in directory tree next to this file and its directory name is `breakhis_400x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path().absolute()\n",
    "input_path = cwd / f'breakhis_{zoom}x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.disable_traceback_filtering()\n",
    "\n",
    "def process_example(image):\n",
    "    inputs = image_processor(image, return_tensors='tf')\n",
    "    return inputs['pixel_values']\n",
    "\n",
    "\n",
    "def process_dataset(example):\n",
    "    example['pixel_values'] = process_example(Image.open(example['file_loc']).convert(\"RGB\"))\n",
    "\n",
    "    example['label'] = to_categorical(example['label'], num_classes=2)\n",
    "    return example\n",
    "\n",
    "def load_data(fold_idx):\n",
    "    train_csv = str(input_path / f\"train_{fold_idx}.csv\")\n",
    "    val_csv = str(input_path / f\"val_{fold_idx}.csv\")\n",
    "    dataset = load_dataset(\n",
    "        'csv', data_files={'train': train_csv, 'val': val_csv})\n",
    "\n",
    "    dataset = dataset.map(process_dataset, with_indices=False, num_proc=4)\n",
    "\n",
    "    print(f\"Loaded {fold_idx} dataset: {dataset}\")\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model using `Keras`\n",
    "\n",
    "Now that our `dataset` is processed, we can download the pretrained model and fine-tune it. But before we can do this we need to convert our Hugging Face `datasets` Dataset into a `tf.data.Dataset`. For this, we will use the `.to_tf_dataset` method and a `data collator` (Data collators are objects that will form a batch by using a list of dataset elements as input).\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070 Laptop GPU, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 18:33:50.505097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:33:50.582637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:33:50.582721: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:33:50.583258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "id2label = {\"0\": \"benign\", \"1\": \"malignant\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "num_train_epochs = 150\n",
    "batch_size = 10\n",
    "batch_size = 10\n",
    "num_warmup_steps = 0\n",
    "fp16 = True\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "if fp16:\n",
    "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the pretrained transformer model and fine-tune it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss():\n",
    "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "def get_metrics():\n",
    "    return [\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        tf.keras.metrics.AUC(name='auc', from_logits=True),\n",
    "        # tf.keras.metrics.AUC(name='auc_multi', from_logits=True,\n",
    "                            #  num_labels=2, multi_label=True),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tfa.metrics.F1Score(name='f1_score', num_classes=2, threshold=0.5),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_callbacks(output_path, fold_idx):\n",
    "    return [\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=3),\n",
    "        CSVLogger(output_path / f'train_metrics_{fold_idx}.csv')\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_optimizer(learning_rate, weight_decay_rate, num_warmup_steps, num_train_steps):\n",
    "    optimizer, _ = create_optimizer(\n",
    "        init_lr=learning_rate,\n",
    "        num_train_steps=num_train_steps,\n",
    "        weight_decay_rate=weight_decay_rate,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "    )\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "num_train_steps_list = []\n",
    "def train_model(fold_idx, train, val, learning_rate, weight_decay_rate, output_path):\n",
    "    num_train_steps = len(train) * num_train_epochs\n",
    "    num_train_steps_list.append(num_train_steps)\n",
    "    print(f\"num_train_steps = {num_train_steps}\")\n",
    "    optimizer = get_optimizer(\n",
    "        learning_rate, weight_decay_rate, num_warmup_steps, num_train_steps)\n",
    "\n",
    "    # load pre-trained ViT model\n",
    "    model = model_arch.from_pretrained(\n",
    "        model_id,\n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes = True\n",
    "    )\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=optimizer, loss=get_loss(), metrics=get_metrics())\n",
    "    \n",
    "    print(f\"MODEL SUMMARY: {model.summary()}\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        callbacks=get_callbacks(output_path, fold_idx),\n",
    "        epochs=num_train_epochs,\n",
    "    )\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_dim(example):\n",
    "    example['pixel_values'] = np.squeeze(example['pixel_values'], axis=0)\n",
    "    return example\n",
    "\n",
    "def save_model(idx, model, output_path):\n",
    "    model.save_pretrained(output_path / f'model_{idx}', from_tf=True)\n",
    "    \n",
    "def save_history(idx, history, output_path):\n",
    "    np.save(output_path / f'train_history_{idx}.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "\n",
    "def run_fold(fold_idx, learning_rate, weight_decay_rate, output_path):\n",
    "    tf.keras.backend.clear_session()\n",
    "    dataset = load_data(fold_idx)\n",
    "\n",
    "    # Check patient ids uniqueness\n",
    "    train_dataset = dataset[\"train\"].map(remove_extra_dim)\n",
    "    val_dataset = dataset[\"val\"].map(remove_extra_dim)\n",
    "\n",
    "    # Create datasets and train model\n",
    "    data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "    train_dataset_tf = train_dataset.to_tf_dataset(\n",
    "        columns=['pixel_values'],\n",
    "        label_cols=['label'],\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    val_dataset_tf = val_dataset.to_tf_dataset(\n",
    "        columns=['pixel_values'],\n",
    "        label_cols=['label'],\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "    print(train_dataset_tf)\n",
    "    print(val_dataset_tf)\n",
    "\n",
    "    model, history = train_model(fold_idx, train_dataset_tf, val_dataset_tf, learning_rate, weight_decay_rate, output_path)\n",
    "    save_model(fold_idx, model, output_path)\n",
    "    save_history(fold_idx, history, output_path)\n",
    "\n",
    "    print(f'Fold {fold_idx} finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_info(output_path, fold_idx, learning_rate, weight_decay_rate):\n",
    "    model_info = {\"idx\": fold_idx,\n",
    "                    \"model_id\": model_id,\n",
    "                    \"zoom\": zoom,\n",
    "                    \"n_splits\": 5,\n",
    "                    \"num_train_epochs\": num_train_epochs,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"weight_decay_rate\": weight_decay_rate,\n",
    "                    \"num_warmup_steps\": num_warmup_steps,\n",
    "                    \"num_train_steps\": num_train_steps_list[0]}\n",
    "\n",
    "    with open(output_path / f'model_info_{fold_idx}.json', 'w') as f:\n",
    "        json.dump(model_info, f, indent=4)\n",
    "\n",
    "    print(json.dumps(model_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file_loc', 'label', 'label_str', 'patient_id', 'pixel_values'],\n",
      "        num_rows: 1077\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['file_loc', 'label', 'label_str', 'patient_id', 'pixel_values'],\n",
      "        num_rows: 354\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n",
      "2023-12-03 18:33:59.530529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:33:59.530708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:33:59.530814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:34:00.584623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:34:00.584844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:34:00.584866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-03 18:34:00.584970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 18:34:00.585324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5593 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3, 224, 224), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n",
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3, 224, 224), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n",
      "num_train_steps = 16200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 18:34:04.424004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2023-12-03 18:34:04.942202: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x806b9d10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-03 18:34:04.942256: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2023-12-03 18:34:05.561471: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Conv._jit_compiled_convolution_op at 0x7f2d8d484ae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Conv._jit_compiled_convolution_op at 0x7f2d8d4605e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFConvNextForImageClassification.\n",
      "\n",
      "Some weights of TFConvNextForImageClassification were not initialized from the model checkpoint at facebook/convnext-base-224-22k and are newly initialized because the shapes did not match:\n",
      "- classifier/kernel:0: found shape (1024, 21841) in the checkpoint and (1024, 2) in the model instantiated\n",
      "- classifier/bias:0: found shape (21841,) in the checkpoint and (2,) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_conv_next_for_image_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convnext (TFConvNextMainLay  multiple                 87566464  \n",
      " er)                                                             \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87,568,514\n",
      "Trainable params: 87,568,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "MODEL SUMMARY: None\n",
      "Epoch 1/150\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8136 - auc: 0.9071 - recall: 0.7467 - precision: 0.8619 - f1_score: 0.7647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 18:35:26.115118: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.4 = (f16[1,7,7,1024]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,7,7,7168]{3,2,1,0} %bitcast.40, f16[1024,7,7,8]{3,2,1,0} %transpose.3), window={size=7x7 pad=3_3x3_3}, dim_labels=b01f_o01i->b01f, feature_group_count=1024, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradients/Conv2D_grad/Conv2DBackpropFilter\" source_file=\"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\" source_line=519}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n",
      "\n",
      "Original error: UNKNOWN: CUDNN_STATUS_BAD_PARAM\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3588): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2023-12-03 18:35:26.115178: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv.4 = (f16[1,7,7,1024]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,7,7,7168]{3,2,1,0} %bitcast.40, f16[1024,7,7,8]{3,2,1,0} %transpose.3), window={size=7x7 pad=3_3x3_3}, dim_labels=b01f_o01i->b01f, feature_group_count=1024, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradients/Conv2D_grad/Conv2DBackpropFilter\" source_file=\"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\" source_line=519}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n",
      "\n",
      "Original error: UNKNOWN: CUDNN_STATUS_BAD_PARAM\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3588): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node AdamWeightDecay/gradients/PartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node 'AdamWeightDecay/gradients/PartitionedCall' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n      app.start()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1364/3407642219.py\", line 16, in <module>\n      run_fold(fold_idx, learning_rate, weight_decay_rate, output_path)\n    File \"/tmp/ipykernel_1364/2688380364.py\", line 34, in run_fold\n      model, history = train_model(fold_idx, train_dataset_tf, val_dataset_tf, learning_rate, weight_decay_rate, output_path)\n    File \"/tmp/ipykernel_1364/4123974316.py\", line 57, in train_model\n      history = model.fit(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 61, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1675, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 585, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/mixed_precision/loss_scale_optimizer.py\", line 744, in _compute_gradients\n      grads_and_vars = self._optimizer._compute_gradients(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 643, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 519, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'AdamWeightDecay/gradients/PartitionedCall'\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv.4 = (f16[1,7,7,1024]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,7,7,7168]{3,2,1,0} %bitcast.40, f16[1024,7,7,8]{3,2,1,0} %transpose.3), window={size=7x7 pad=3_3x3_3}, dim_labels=b01f_o01i->b01f, feature_group_count=1024, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradients/Conv2D_grad/Conv2DBackpropFilter\" source_file=\"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\" source_line=519}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: UNKNOWN: CUDNN_STATUS_BAD_PARAM\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3588): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node AdamWeightDecay/gradients/PartitionedCall}}]] [Op:__inference_train_function_46170]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# shutil.rmtree(output_path, ignore_errors=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(output_path)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m run_fold(fold_idx, learning_rate, weight_decay_rate, output_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m save_model_info(output_path, fold_idx, learning_rate, weight_decay_rate)\n",
      "\u001b[1;32m/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(train_dataset_tf)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(val_dataset_tf)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m model, history \u001b[39m=\u001b[39m train_model(fold_idx, train_dataset_tf, val_dataset_tf, learning_rate, weight_decay_rate, output_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m save_model(fold_idx, model, output_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m save_history(fold_idx, history, output_path)\n",
      "\u001b[1;32m/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, loss\u001b[39m=\u001b[39mget_loss(), metrics\u001b[39m=\u001b[39mget_metrics())\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMODEL SUMMARY: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39msummary()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     train,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mget_callbacks(output_path, fold_idx),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_train_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/miki/repos/uz/breakhis/vcs/train_models_with_predefined_folds_deit.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:141\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_traceback_filtering_enabled():\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m   \u001b[39m# In some very rare cases,\u001b[39;00m\n\u001b[1;32m    144\u001b[0m   \u001b[39m# `is_traceback_filtering_enabled` (from the outer scope) may not be\u001b[39;00m\n\u001b[1;32m    145\u001b[0m   \u001b[39m# accessible from inside this function\u001b[39;00m\n\u001b[1;32m    146\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'AdamWeightDecay/gradients/PartitionedCall' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n      app.start()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1364/3407642219.py\", line 16, in <module>\n      run_fold(fold_idx, learning_rate, weight_decay_rate, output_path)\n    File \"/tmp/ipykernel_1364/2688380364.py\", line 34, in run_fold\n      model, history = train_model(fold_idx, train_dataset_tf, val_dataset_tf, learning_rate, weight_decay_rate, output_path)\n    File \"/tmp/ipykernel_1364/4123974316.py\", line 57, in train_model\n      history = model.fit(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 61, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/transformers/modeling_tf_utils.py\", line 1675, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 585, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/mixed_precision/loss_scale_optimizer.py\", line 744, in _compute_gradients\n      grads_and_vars = self._optimizer._compute_gradients(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 643, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 519, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'AdamWeightDecay/gradients/PartitionedCall'\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv.4 = (f16[1,7,7,1024]{3,2,1,0}, u8[0]{0}) custom-call(f16[1,7,7,7168]{3,2,1,0} %bitcast.40, f16[1024,7,7,8]{3,2,1,0} %transpose.3), window={size=7x7 pad=3_3x3_3}, dim_labels=b01f_o01i->b01f, feature_group_count=1024, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradients/Conv2D_grad/Conv2DBackpropFilter\" source_file=\"/home/miki/miniconda3/envs/tf3/lib/python3.11/site-packages/keras/optimizers/legacy/optimizer_v2.py\" source_line=519}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: UNKNOWN: CUDNN_STATUS_BAD_PARAM\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(3588): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node AdamWeightDecay/gradients/PartitionedCall}}]] [Op:__inference_train_function_46170]"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['XLA_FLAGS'] = '--xla_gpu_strict_conv_algorithm_picker=false'\n",
    "\n",
    "experiment_id = \"convnextttttt\"\n",
    "fold_idx = 0\n",
    "learning_rate = 3e-5\n",
    "# learning_rate = 1e-4\n",
    "# weight_decay_rate = 0.01\n",
    "weight_decay_rate = 0.005\n",
    "\n",
    "output_path = cwd / 'results' / f'{zoom}x_{experiment_id}'\n",
    "\n",
    "# shutil.rmtree(output_path, ignore_errors=True)\n",
    "os.makedirs(output_path)\n",
    "\n",
    "run_fold(fold_idx, learning_rate, weight_decay_rate, output_path)\n",
    "save_model_info(output_path, fold_idx, learning_rate, weight_decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--experiment_id', default='224x224frames_convnext', type=str)\n",
    "#     parser.add_argument('--fold_idx', default=0, type=int)\n",
    "#     parser.add_argument('--weight_decay_rate', default=0.005, type=float)\n",
    "#     parser.add_argument('--learning_rate', default=3e-5, type=float)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     experiment_id = args.experiment_id\n",
    "#     fold_idx = args.fold_idx\n",
    "#     weight_decay_rate = args.weight_decay_rate\n",
    "#     learning_rate = args.learning_rate\n",
    "    \n",
    "#     cwd = Path.cwd()\n",
    "#     output_path = cwd / 'results' / f'{experiment_id}'\n",
    "    \n",
    "#     os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "#     run_fold(fold_idx, learning_rate, weight_decay_rate, output_path)\n",
    "#     save_model_info(output_path, fold_idx, learning_rate, weight_decay_rate)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "ec1370a512a4612a2908be3c3c8b0de1730d00dc30104daff827065aeaf438b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
